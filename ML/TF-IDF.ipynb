{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Text Files and Split the Document Texts into Words \n",
    "### Read Text Files from 5 Subdirectories\n",
    "In order to process the data, the first step is to read the data. The data in this task is stored in five folders. Therefore, you need to read the data in the five folders separately and write the file path to a list for easy access. To obtain the pathnames in bulk, you need to construct a function that concatenates the upper-layer path of the file with the filename obtained using the **os.listdir()** function in the os package. In the report is the **write_path(top path,name)** custom function. Each file path name is generated and written into a list to read at one time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: mathew <mathew@mantis.co.uk>\n",
      "Subject: Alt.Atheism FAQ: Atheist Resources\n",
      "Summary: Books, addresses, music -- anything related to atheism\n",
      "Keywords: FAQ, atheism, books, music, fiction, addresses, contacts\n",
      "Expires: Thu, 29 Apr 1993 11:57:19 GMT\n",
      "Distribution: world\n",
      "Organization: Mantis Consultants, Cambridge. UK.\n",
      "Supersedes: <19930301143317@mantis.co.uk>\n",
      "Lines: 290\n",
      "\n",
      "Archive-name: atheism/resources\n",
      "Alt-atheism-archive-name: resources\n",
      "Last-modified: 11 December 1992\n",
      "Version: 1.0\n",
      "\n",
      "              \n"
     ]
    }
   ],
   "source": [
    "#Read Files\n",
    "import os\n",
    "###使用os.os.listdir()\n",
    "files1= os.listdir('E:/mlhomework/dataset-temp/documents-export-2023-10-23/dataset/alt.atheism/')\n",
    "files2= os.listdir('E:/mlhomework/dataset-temp/documents-export-2023-10-23/dataset/comp.graphics/')\n",
    "files3= os.listdir('E:/mlhomework/dataset-temp/documents-export-2023-10-23/dataset/rec.motorcycles/')\n",
    "files4= os.listdir('E:/mlhomework/dataset-temp/documents-export-2023-10-23/dataset/soc.religion.christian/')\n",
    "files5= os.listdir('E:/mlhomework/dataset-temp/documents-export-2023-10-23/dataset/talk.politics.misc/')\n",
    "files=[]\n",
    "\n",
    "def write_path(top_path,name):    ###Construct a function that gets the pathname\n",
    "    path=[]\n",
    "    for i in name:\n",
    "        path.append(top_path+str(i))\n",
    "    return path\n",
    "\n",
    "p1=write_path('E:/mlhomework/dataset-temp/documents-export-2023-10-23/dataset/alt.atheism/',files1)\n",
    "p2=write_path('E:/mlhomework/dataset-temp/documents-export-2023-10-23/dataset/comp.graphics/',files2)\n",
    "p3=write_path('E:/mlhomework/dataset-temp/documents-export-2023-10-23/dataset/rec.motorcycles/',files3)\n",
    "p4=write_path('E:/mlhomework/dataset-temp/documents-export-2023-10-23/dataset/soc.religion.christian/',files4)\n",
    "p5=write_path('E:/mlhomework/dataset-temp/documents-export-2023-10-23/dataset/talk.politics.misc/',files5)\n",
    "\n",
    "files_paths=p1+p2+p3+p4+p5 ##Write five paths to a list\n",
    "\n",
    "#Build Text Database\n",
    "textbase=[]\n",
    "for i in files_paths:\n",
    "    with open(i,'r',encoding='Latin1') as file: \n",
    "        content=file.read()\n",
    "        textbase.append(content)\n",
    "print(textbase[0][0:500]) #See if the first 500 characters of the first article were read successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2726"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_paths) ### check the number of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Document Text into Words \n",
    "In order to extract stem, calculate word frequency, and so on, we need to break down the whole text into individual words. Since the subsequent calculation of $a_ik$ and $n_k$ is different, it is easier to construct a list of all file terms and a list of file-specific terms here. It is recorded as a list of terms for each file using list nesting, i.e. $[[words_{doc1}],[words_{doc2}]...]$.\n",
    "\n",
    "In order to better calculate word frequency, we need to remove all non-word characters in the text, including numbers, punctuation, and null values. This report uses the **re.sub()** function in the re package to eliminate all non-word characters using regular expressions. We use **str.lower()** to convert all uppercase letters to lowercase, and then we use the **split()** function to split words using Spaces as delimiters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'mathew', 'mathew', 'mantis', 'co', 'uk', 'subject', 'alt', 'atheism', 'faq', 'atheist', 'resources', 'summary', 'books', 'addresses', 'music', 'anything', 'related', 'to', 'atheism', 'keywords', 'faq', 'atheism', 'books', 'music', 'fiction', 'addresses', 'contacts', 'expires', 'thu', 'apr', 'gmt', 'distribution', 'world', 'organization', 'mantis', 'consultants', 'cambridge', 'uk', 'supersedes', 'mantis', 'co', 'uk', 'lines', 'archive', 'name', 'atheism', 'resources', 'alt', 'atheism']\n",
      "['from', 'mathew', 'mathew', 'mantis', 'co', 'uk', 'subject', 'alt', 'atheism', 'faq']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "wordsbase=[]\n",
    "total_doc_words=[]\n",
    "words_by_text=[]\n",
    "for i in textbase:  ###Build a list of all file's words\n",
    "    total_doc_words.extend(re.sub(r'[^a-z]',' ' ,i.lower()).strip().split(' '))###Remove all punctuation marks, convert them to \n",
    "total_doc_words=list(filter(None, total_doc_words)) ### Revmove Null           ###lower case and add them to the list\n",
    "print(total_doc_words[0:50])\n",
    "\n",
    "#important⬇⬇⬇\n",
    "for i in textbase: ###Build a list of words by article \n",
    "    wordsbase.append(re.sub(r'[^a-z]',' ' ,i.lower()).strip().split(' '))\n",
    "for k in wordsbase:\n",
    "    c=list(filter(None, k))\n",
    "    words_by_text.append(c)\n",
    "print(words_by_text[0][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the stopwords\n",
    "In order to get rid of the words that we don't need for research, we need to load the stop vocabulary to remove the words that we don't need, which are frequent words that carry no\n",
    " informatio,n from the list and prevent them from affecting the subsequent research of other words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'above', 'abroad', 'according', 'accordingly', 'across', 'actually', 'adj', 'after']\n"
     ]
    }
   ],
   "source": [
    "with open(\"E:/mlhomework/dataset-temp/documents-export-2023-10-23/stopwords.txt\", \"r\") as f:  # open the stopwords file\n",
    "    stopwords = f.read().split('\\n') #read the file\n",
    "print(stopwords[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the stopwords from the text collections \n",
    "Use the $for$ loop statement to remove words from the stop words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mathew', 'mathew', 'mantis', 'uk', 'subject', 'alt', 'atheism', 'faq', 'atheist', 'resources', 'summary', 'books', 'addresses', 'music', 'atheism', 'keywords', 'faq', 'atheism', 'books', 'music', 'fiction', 'addresses', 'contacts', 'expires', 'thu', 'apr', 'gmt', 'distribution', 'organization', 'mantis', 'consultants', 'cambridge', 'uk', 'supersedes', 'mantis', 'uk', 'lines', 'archive', 'atheism', 'resources', 'alt', 'atheism', 'archive', 'resources', 'modified', 'december', 'version', 'atheist', 'resources', 'addresses']\n",
      "['mathew', 'mathew', 'mantis', 'uk', 'subject', 'alt', 'atheism', 'faq', 'atheist', 'resources', 'summary', 'books', 'addresses', 'music', 'atheism', 'keywords', 'faq', 'atheism', 'books', 'music', 'fiction', 'addresses', 'contacts', 'expires', 'thu', 'apr', 'gmt', 'distribution', 'organization', 'mantis', 'consultants', 'cambridge', 'uk', 'supersedes', 'mantis', 'uk', 'lines', 'archive', 'atheism', 'resources', 'alt', 'atheism', 'archive', 'resources', 'modified', 'december', 'version', 'atheist', 'resources', 'addresses']\n"
     ]
    }
   ],
   "source": [
    "###The total words list removes stopwords\n",
    "filtered_total_doc_words = [i for i in total_doc_words if not i in stopwords]\n",
    "filtered_words_by_text=[]\n",
    "###The words by text list removes stopwords\n",
    "for i in words_by_text:\n",
    "    filtered_text = [w for w in i if not w in stopwords]\n",
    "    filtered_words_by_text.append(filtered_text)\n",
    "print(filtered_words_by_text[0][0:50])\n",
    "print(filtered_total_doc_words[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Perform word stemming to remove the word suffix \n",
    "\n",
    "In English, one word is often a variant of another. Word has, plurality, temporal difference, lead to such as \"cat, cats/watch, watching/happy, happiness\" can be as different word word frequency calculation, so we will need stemming to better access to the actual frequency words.\n",
    "In information retrieval system, one thing we often do is to extract stemming, that is, to remove the end of English word segmentation transformation form, in the process of Term normalization. For exmaple,happy is called the stem of happiness. \n",
    "To extract the stem, we used the nLTk.stem.porter section of the nltk package to extract the stem. Using $PorterStemmer()$, a stem-extraction algorithm based on suffix stripping, the Porter stemmer algorithm, also known as the Porter stemmer. This method is moderately complex and widely used in stem extraction in natural language processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mathew', 'mathew', 'manti', 'uk', 'subject', 'alt', 'atheism', 'faq', 'atheist', 'resourc', 'summari', 'book', 'address', 'music', 'atheism', 'keyword', 'faq', 'atheism', 'book', 'music', 'fiction', 'address', 'contact', 'expir', 'thu', 'apr', 'gmt', 'distribut', 'organ', 'manti', 'consult', 'cambridg', 'uk', 'supersed', 'manti', 'uk', 'line', 'archiv', 'atheism', 'resourc', 'alt', 'atheism', 'archiv', 'resourc', 'modifi', 'decemb', 'version', 'atheist', 'resourc', 'address']\n",
      "['mathew', 'mathew', 'manti', 'uk', 'subject', 'alt', 'atheism', 'faq', 'atheist', 'resourc', 'summari', 'book', 'address', 'music', 'atheism', 'keyword', 'faq', 'atheism', 'book', 'music', 'fiction', 'address', 'contact', 'expir', 'thu', 'apr', 'gmt', 'distribut', 'organ', 'manti', 'consult', 'cambridg', 'uk', 'supersed', 'manti', 'uk', 'line', 'archiv', 'atheism', 'resourc', 'alt', 'atheism', 'archiv', 'resourc', 'modifi', 'decemb', 'version', 'atheist', 'resourc', 'address']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *    ###Stem extraction\n",
    "### Porter's stem\n",
    "stemmer=PorterStemmer()  \n",
    "### Total words list after stem extraction\n",
    "singles= [stemmer.stem(filtered_total_doc_words) for filtered_total_doc_words in filtered_total_doc_words]\n",
    "print(singles[0:50])\n",
    "\n",
    "###The words by text list after stem extraction\n",
    "stem_words_by_text=[]\n",
    "for i in filtered_words_by_text:\n",
    "    stem_words= [stemmer.stem(i) for i in i]\n",
    "    stem_words_by_text.append(stem_words)\n",
    "print(stem_words_by_text[0][0:50])  #View the word list of first text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $f_{ik}$: the Frequency of Word k in Document i\n",
    "\n",
    "In order to calculate the word frequency, we need to define a word frequency count function $count(input-text)$, calculate the word frequency, the word in each list and the word corresponding word frequency input into the dict to save. In this way, with the word as the key, its corresponding value is the word frequency. The function **count(input-text)** will enter the dict word for the first time as the key, and update its value count each time after the loop, and finally stored in dict form. In the case of **words_freq_by_text** , because we need to annotate the text file from which the text comes, this report uses nested dict to store the data. For example, \n",
    "\n",
    "$\\{\\{doc1: \\{word_1 : 32, word_2 : 41... \\},doc2:\\{word_1 : 12,word_3 : 16.. \\},doc3:\\{... \\}... \\}\\} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('49960', {'mathew': 3, 'manti': 5, 'uk': 5, 'subject': 2, 'alt': 3, 'atheism': 13, 'faq': 2, 'atheist': 11, 'resourc': 5, 'summari': 1, 'book': 17, 'address': 5, 'music': 3, 'keyword': 1, 'fiction': 3, 'contact': 1, 'expir': 1, 'thu': 1, 'apr': 1, 'gmt': 1, 'distribut': 1, 'organ': 3, 'consult': 1, 'cambridg': 1, 'supersed': 1, 'line': 2, 'archiv': 5, 'modifi': 1, 'decemb': 1, 'version': 4, 'usa': 4, 'freedom': 2, 'religion': 6, 'foundat': 2, 'darwin': 4, 'fish': 6, 'bumper': 1, 'sticker': 1, 'assort': 3, 'paraphernalia': 1, 'write': 8, 'ffrf': 1, 'box': 3, 'madison': 1, 'wi': 1, 'telephon': 4, 'evolut': 3, 'design': 3, 'sell': 2, 'symbol': 1, 'christian': 10, 'stick': 1, 'car': 1, 'feet': 1, 'word': 1, 'written': 2, 'delux': 1, 'mould': 1, 'plastic': 1, 'postpaid': 1, 'laurel': 1, 'canyon': 1, 'north': 1, 'hollywood': 1, 'peopl': 6, 'san': 1, 'francisco': 1, 'bay': 1, 'area': 2, 'lynn': 2, 'gold': 1, 'mail': 4, 'figmo': 1, 'netcom': 1, 'net': 2, 'price': 1, 'american': 8, 'press': 8, 'aap': 2, 'publish': 4, 'critiqu': 2, 'bibl': 8, 'list': 2, 'biblic': 1, 'contradict': 3, 'handbook': 1, 'ball': 2, 'foot': 2, 'isbn': 5, 'edit': 3, 'absurd': 1, 'atroc': 1, 'immor': 2, 'base': 4, 'king': 1, 'jame': 3, 'austin': 2, 'tx': 2, 'cameron': 1, 'road': 2, 'fax': 2, 'prometheu': 5, 'includ': 5, 'haught': 2, 'holi': 2, 'horror': 2, 'east': 1, 'amherst': 1, 'street': 2, 'buffalo': 3, 'york': 2, 'altern': 2, 'newer': 1, 'older': 1, 'glenn': 1, 'drive': 1, 'ny': 2, 'african': 4, 'human': 5, 'promot': 1, 'black': 2, 'secular': 4, 'uncov': 1, 'histori': 6, 'freethought': 2, 'quarterli': 1, 'newslett': 1, 'aah': 1, 'examin': 2, 'norm': 2, 'allen': 2, 'jr': 3, 'unit': 1, 'kingdom': 1, 'rationalist': 1, 'associ': 2, 'nation': 3, 'societi': 3, 'islington': 1, 'high': 1, 'holloway': 1, 'london': 4, 'ew': 1, 'nl': 1, 'british': 1, 'humanist': 1, 'south': 1, 'place': 1, 'ethic': 1, 'lamb': 1, 'conduit': 1, 'passag': 1, 'conway': 1, 'hall': 1, 'wc': 2, 'rh': 1, 'red': 1, 'lion': 1, 'squar': 1, 'rl': 1, 'freethink': 1, 'monthli': 1, 'magazin': 1, 'found': 1, 'germani': 4, 'ibka': 3, 'international': 2, 'bund': 1, 'der': 3, 'konfessionslosen': 2, 'und': 3, 'atheisten': 2, 'postfach': 3, 'berlin': 2, 'journal': 2, 'miz': 2, 'materialien': 1, 'informationen': 1, 'zur': 1, 'zeit': 1, 'politisch': 1, 'konfessionslosesn': 1, 'hrsg': 1, 'vertrieb': 1, 'ibdk': 1, 'ucherdienst': 1, 'hannov': 1, 'thoma': 1, 'disch': 1, 'santa': 2, 'clau': 1, 'compromis': 1, 'short': 2, 'stori': 4, 'ultim': 2, 'proof': 1, 'exist': 9, 'charact': 2, 'event': 1, 'fictiti': 1, 'similar': 1, 'live': 3, 'dead': 2, 'god': 16, 'uh': 1, 'walter': 1, 'miller': 1, 'canticl': 1, 'leibowitz': 2, 'gem': 1, 'post': 2, 'atom': 3, 'doomsday': 2, 'monk': 1, 'spent': 1, 'copi': 1, 'blueprint': 1, 'saint': 1, 'fill': 1, 'sheet': 1, 'paper': 3, 'ink': 1, 'leav': 1, 'white': 1, 'letter': 1, 'edgar': 1, 'pangborn': 1, 'davi': 1, 'set': 2, 'cleric': 1, 'church': 1, 'forbid': 1, 'produc': 1, 'substanc': 1, 'philip': 3, 'dick': 3, 'wrote': 3, 'philosoph': 3, 'thought': 2, 'provok': 1, 'novel': 2, 'bizarr': 1, 'time': 2, 'approach': 1, 'sf': 1, 'truth': 1, 'technolog': 2, 'believ': 2, 'met': 1, 'sort': 1, 'remain': 1, 'sceptic': 1, 'relev': 1, 'galact': 1, 'pot': 2, 'healer': 2, 'fallibl': 1, 'alien': 1, 'deiti': 2, 'summon': 1, 'group': 1, 'earth': 2, 'craftsmen': 1, 'women': 2, 'remot': 1, 'planet': 1, 'rais': 1, 'giant': 1, 'cathedr': 1, 'beneath': 1, 'ocean': 1, 'demand': 1, 'faith': 2, 'earther': 1, 'joe': 1, 'fernwright': 1, 'unabl': 1, 'compli': 1, 'polish': 1, 'iron': 1, 'amus': 1, 'maze': 1, 'death': 1, 'noteworthi': 1, 'descript': 1, 'vali': 1, 'schizophren': 1, 'hero': 1, 'search': 1, 'hidden': 1, 'mysteri': 2, 'gnostic': 1, 'realiti': 1, 'fire': 1, 'brain': 2, 'pink': 1, 'laser': 1, 'beam': 1, 'unknown': 1, 'divin': 2, 'origin': 2, 'accompani': 1, 'dogmat': 1, 'dismiss': 1, 'friend': 1, 'odd': 1, 'invas': 1, 'invad': 1, 'make': 1, 'young': 1, 'woman': 2, 'pregnant': 1, 'return': 1, 'star': 1, 'termin': 1, 'ill': 1, 'assist': 1, 'man': 1, 'wire': 1, 'hour': 1, 'easi': 1, 'listen': 1, 'margaret': 1, 'atwood': 2, 'handmaid': 1, 'tale': 2, 'premis': 1, 'congress': 2, 'assassin': 1, 'fundamentalist': 2, 'charg': 1, 'diari': 1, 'life': 1, 'theocraci': 1, 'properti': 1, 'revok': 1, 'bank': 1, 'account': 1, 'close': 1, 'sin': 1, 'luxuri': 1, 'outlaw': 1, 'radio': 1, 'read': 3, 'crime': 1, 'punish': 1, 'retroact': 1, 'doctor': 1, 'perform': 1, 'legal': 1, 'abort': 1, 'hunt': 1, 'hang': 1, 'style': 1, 'difficult': 1, 'grow': 1, 'chill': 1, 'author': 1, 'dull': 1, 'rambl': 1, 'work': 3, 'critic': 1, 'worth': 1, 'll': 1, 'fuss': 1, 'true': 1, 'peter': 1, 'rosa': 2, 'vicar': 1, 'christ': 1, 'bantam': 1, 'cathol': 1, 'enlight': 1, 'papal': 1, 'adulteri': 1, 'fallaci': 1, 'german': 1, 'translat': 1, 'gott': 1, 'erst': 1, 'diener': 1, 'die': 1, 'dunkl': 1, 'seit': 1, 'de': 1, 'papsttum': 1, 'droemer': 1, 'knaur': 1, 'michael': 1, 'martin': 2, 'justif': 2, 'templ': 2, 'univers': 3, 'philadelphia': 1, 'detail': 1, 'scholarli': 1, 'outstand': 1, 'appendix': 2, 'defin': 1, 'terminolog': 1, 'usag': 1, 'tendenti': 2, 'argu': 1, 'neg': 1, 'belief': 3, 'posit': 3, 'great': 3, 'refut': 2, 'challeng': 1, 'argument': 5, 'attent': 1, 'paid': 1, 'contempori': 1, 'theist': 1, 'platinga': 1, 'swinburn': 6, 'hardcov': 2, 'paperback': 2, 'case': 1, 'comprehens': 3, 'consid': 1, 'contemporari': 1, 'defenc': 1, 'demonstr': 1, 'unsupport': 1, 'incoher': 2, 'turner': 1, 'creed': 2, 'john': 1, 'hopkin': 1, 'baltimor': 1, 'md': 1, 'subtitl': 1, 'unbelief': 2, 'america': 1, 'agnost': 1, 'mainstream': 1, 'view': 3, 'focuss': 1, 'period': 1, 'franc': 1, 'britain': 1, 'emphasi': 1, 'england': 1, 'develop': 1, 'religi': 3, 'intellectu': 1, 'fate': 1, 'singl': 1, 'idea': 2, 'georg': 1, 'seld': 1, 'editor': 1, 'ballantin': 1, 'dictionari': 1, 'quotat': 2, 'kind': 1, 'concentr': 1, 'statement': 1, 'explicitli': 1, 'implicitli': 1, 'person': 1, 'philosophi': 1, 'obscur': 1, 'suppress': 1, 'opinion': 1, 'popular': 1, 'observ': 1, 'trace': 1, 'express': 1, 'twist': 1, 'centuri': 2, 'number': 2, 'deriv': 1, 'cardiff': 1, 'men': 1, 'noy': 1, 'richard': 1, 'revis': 2, 'clarendon': 1, 'oxford': 2, 'volum': 2, 'trilog': 1, 'began': 1, 'coher': 1, 'theism': 3, 'conclud': 1, 'reason': 1, 'attempt': 2, 'construct': 1, 'seri': 1, 'induct': 1, 'reli': 1, 'imput': 1, 'late': 1, 'western': 1, 'valu': 1, 'aesthet': 1, 'supposedli': 1, 'simpl': 1, 'conceiv': 1, 'decis': 1, 'reject': 1, 'macki': 3, 'miracl': 2, 'rebut': 1, 'posthum': 1, 'review': 1, 'princip': 1, 'rang': 2, 'classic': 2, 'descart': 1, 'anselm': 1, 'berkeley': 1, 'hume': 1, 'al': 1, 'moral': 2, 'newman': 1, 'kant': 1, 'sidgwick': 1, 'restat': 1, 'these': 1, 'plantinga': 1, 'push': 1, 'concept': 1, 'realm': 1, 'ration': 2, 'kierkegaard': 1, 'kung': 1, 'replac': 1, 'leli': 1, 'axiarch': 1, 'delight': 1, 'formalist': 1, 'refreshingli': 1, 'direct': 1, 'compar': 1, 'hand': 1, 'wave': 1, 'illustr': 1, 'murder': 1, 'mad': 1, 'persecut': 1, 'ancient': 1, 'day': 1, 'librari': 1, 'catalog': 1, 'card': 1, 'antholog': 3, 'gordon': 1, 'stein': 1, 'cover': 1, 'wide': 1, 'devil': 1, 'evil': 1, 'bibliographi': 1, 'edmund': 1, 'cohen': 1, 'mind': 1, 'studi': 1, 'small': 1, 'server': 2, 'carri': 1, 'moder': 1, 'articl': 1, 'file': 1, 'send': 2, 'repli': 1})\n"
     ]
    }
   ],
   "source": [
    "###Customize a word frequency counting function\n",
    "def count(input_text):  #Count word frequency \n",
    "    word_dict = {} \n",
    "    for i in input_text:\n",
    "        if i in word_dict.keys():\n",
    "            word_dict[i] += 1\n",
    "        else:\n",
    "            word_dict.update({i:1})\n",
    "    new_word_dict = word_dict.copy()\n",
    "    return new_word_dict\n",
    "\n",
    "text_name=files1+files2+files3+files4+files5\n",
    "\n",
    "def words_freq(text_name,text): ## Record word frequency in dict format\n",
    "    words_freq={}\n",
    "    for i in range(len(text)):\n",
    "        words_freq.update({text_name[i]:count(text[i])})\n",
    "    return words_freq\n",
    "\n",
    "words_freq_by_text=words_freq(text_name,stem_words_by_text)\n",
    "### check this dict\n",
    "print(list(words_freq_by_text.items())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $N$: the number of documents in the dataset\n",
    "\n",
    "$N$ is the total number of texts, and you just use the **len()** function.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2726"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coumpute $n_k$: the total number of documents that word k occurs in the dataset called the document frequency\n",
    "\n",
    "$n_k$ is the total number of documents that word k occurs in the dataset called the document frequency. The method of calculating $n_k$and the previous calculation The method of $f_{ik}$ is the same, and can be calculated using the previously written word frequency counting function **count(input_text)**.\n",
    "The difference is that the storage of $n_k$does not require nested dict, only one layer of dict.\n",
    "\n",
    "$n_k$ is the total number of documents that word k occurs in the dataset called the document frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mathew', 102), ('manti', 85), ('uk', 567), ('subject', 3005), ('alt', 149), ('atheism', 327), ('faq', 216), ('atheist', 611), ('resourc', 104), ('summari', 133), ('book', 547), ('address', 231), ('music', 37), ('keyword', 203), ('fiction', 29), ('contact', 176), ('expir', 24), ('thu', 25), ('apr', 1073), ('gmt', 109), ('distribut', 491), ('organ', 2807), ('consult', 59), ('cambridg', 43), ('supersed', 11), ('line', 2854), ('archiv', 115), ('modifi', 30), ('decemb', 29), ('version', 415), ('usa', 296), ('freedom', 124), ('religion', 522), ('foundat', 80), ('darwin', 7), ('fish', 28), ('bumper', 9), ('sticker', 27), ('assort', 7), ('paraphernalia', 2), ('write', 2608), ('ffrf', 1), ('box', 116), ('madison', 19), ('wi', 8), ('telephon', 26), ('evolut', 46), ('design', 170), ('sell', 125), ('symbol', 24)]\n"
     ]
    }
   ],
   "source": [
    "n_k=count(singles)   #Use the previous custom function count to compute n_k. Singles is the total file after summary\n",
    "print(list(n_k.items())[0:50]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coumpute $a_{ik}$ \n",
    "\n",
    "In order to calculate $a_{ik}$ more easily and intuitively, this report writes the corresponding fik and nk into the same dict for easy calculation. First, construct a custom function **get_value(nk,fik)** to fetch the values of $f_{ik}$and $n_k$ from two dictionaries (words_freq_by_text: $f_{ik}$ and nk :$n_k$) and write them to a double-layer dict store. Loop through fik first, then nk, combining $f_{  ik}$and $ n_k$for each word into a list, then building dict with the word as key and the list as value. Its format\n",
    "\n",
    "$\\{\\{doc1: \\{word_1: [32,2], word_2: [41,7]... \\},doc2:\\{word_1: [12,1],word_3: [16,2]... \\},doc3:\\{... \\}... \\}\\}$\n",
    "\n",
    "Note: Because the resulting dict will not contain words other than those in this text, no $f_{ik}$ value will equal 0, so no 0 will appear when $a_{ik}$ is computed later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Write the corresponding fik and nk into the same dict for easy calculation and storage\n",
    "###words_freq_by_text --> fik {'409960':{'a':1,'b':2,'c':3},'409961':{'d':5,'e':2}}\n",
    "### nk {'a':10,'b':11,'c':12,'d':10,'e':15}\n",
    "\n",
    "def get_value(nk,fik):\n",
    "    dic2={}\n",
    "    for i1 in fik:  \n",
    "        dic1 = {}  #IMPORTRANT Empty the dictionary in the outer layer and initialize the loop\n",
    "        for i2 in nk:\n",
    "            if i2 in fik.get(i1):\n",
    "                dic1.update({i2:[nk.get(i2),fik.get(i1).get(i2)]}) #The fik and nk of each word are included in the key-value pair as a list\n",
    "        dic2.update({i1:dic1}) #Enter the document name and form the data format {file number: {word: [fik,nk]}}\n",
    "    return dic2\n",
    "nk_fik_dic=get_value(n_k,words_freq_by_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the actual data is too large to show, use the following example to view the dict after it has been collated by the **get_value()** function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'409960': {'a': [10, 1], 'b': [11, 2], 'c': [12, 3]}, '409961': {'d': [10, 5], 'e': [15, 2]}}\n"
     ]
    }
   ],
   "source": [
    "### example \n",
    "f_ik1={'409960':{'a':1,'b':2,'c':3},'409961':{'d':5,'e':2}}\n",
    "n_k1={'a':10,'b':11,'c':12,'d':10,'e':15}\n",
    "example=get_value(n_k1,f_ik1)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $a_{ik}$\n",
    "After generating a dict containing $f_{ik}$ and $n_k$ , we can calculate $a_{ik}$ much more easily. We only need to define a function to compute the value of $a_{ik}$, store $a_{ik}$ in the same format in the file-separated dict, and then proceed to the next step.\n",
    "The formula for calculating $a_{ik}$ is as follows:\n",
    "\n",
    "$a_{ik} = log(f_{ik} + 1.0) ∗ log(N/{n_k})$\n",
    "\n",
    "After the calculation is written to the dict in the following format:\n",
    "\n",
    "$\\{\\{doc1: \\{word_1: a_{11}, word_2:a_{12}... \\},doc2:\\{word_1: a_{21},word_3: a_{22}... \\},doc3:\\{... \\}... \\}\\}$\n",
    "\n",
    "This format is very convenient for us to query the $a_{ik}$ value of a word in a document.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Compute aik\n",
    "import math\n",
    "def aik(fik,nk,n):\n",
    "    a_ik=math.log(fik+1)*math.log(n/nk) #Use the log() function in the math library to calculate the logarithm\n",
    "    return a_ik\n",
    "\n",
    "###the entry aik is 0 if the word k is not included in the document i\n",
    "###To increase the speed of operation the word k not included in the document i is not in the dict\n",
    "###So you don't need to worry about whether aik is 0 or not\n",
    "\n",
    "def aik_dic(dic,n):\n",
    "    dic2={}\n",
    "    for i1 in dic:\n",
    "        dic1={}\n",
    "        for i2 in dic.get(i1):\n",
    "            k=dic.get(i1).get(i2)\n",
    "            v=aik(k[1],k[0],n)\n",
    "            dic1.update({i2:v})\n",
    "        dic2.update({i1:dic1})\n",
    "    return dic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mathew': 7.519858958979399, 'manti': 10.045953085666858, 'uk': 6.645716722198903, 'subject': 2.2426759040388595, 'alt': 6.994490143089284, 'atheism': 11.24091758530694, 'faq': 5.135052284083036, 'atheist': 9.030914795265115, 'resourc': 9.684484170628146, 'summari': 3.5759846350033957, 'book': 10.824313973115716, 'address': 8.254612074639406, 'music': 8.925637549602687, 'keyword': 3.282882601077032, 'fiction': 9.26336946903541, 'contact': 3.381809941893074, 'expir': 4.762857293010677, 'thu': 4.734561642604129, 'apr': 2.1287871641349585, 'gmt': 3.7139217875910897, 'distribut': 2.6706685685060894, 'organ': 2.9244334960416065, 'consult': 4.139382762313235, 'cambridg': 4.358651089469357, 'supersed': 5.303621997565879, 'line': 2.2993160129513073, 'archiv': 9.504338471122017, 'modifi': 4.6081859695571, 'decemb': 4.631684734517705, 'version': 6.4717524857276345, 'usa': 7.015612241732095, 'freedom': 5.744778634963161, 'religion': 7.378379198634354, 'foundat': 6.226250887653522, 'darwin': 13.042070914819144, 'fish': 13.071067492231844, 'bumper': 5.442716324346473, 'sticker': 4.6812163139276635, 'assort': 11.233828423486834, 'paraphernalia': 6.485263331265889, 'write': 4.796685180180026, 'ffrf': 6.965716345184091, 'box': 7.341557413362605, 'madison': 4.924786768444069, 'wi': 5.524357303429486, 'telephon': 10.930188392236992, 'evolut': 8.623808711665166, 'design': 6.811704277237056, 'sell': 5.735954392431854, 'symbol': 4.762857293010677, 'christian': 6.824407323933642, 'stick': 4.127732955638899, 'car': 3.3360913624827258, 'feet': 4.093914190905799, 'word': 2.954544741100027, 'written': 5.293438987943122, 'delux': 5.524357303429486, 'mould': 6.965716345184091, 'plastic': 4.48181029651007, 'postpaid': 6.965716345184091, 'laurel': 6.485263331265889, 'canyon': 5.369685979975908, 'north': 3.8165443764009273, 'hollywood': 5.187828929780583, 'peopl': 4.66777118785387, 'san': 3.6648289089429653, 'francisco': 4.282404279092476, 'bay': 4.762857293010677, 'area': 5.042431460904036, 'lynn': 7.994399156101974, 'gold': 4.585457796316283, 'mail': 6.337865246100681, 'figmo': 6.965716345184091, 'netcom': 3.2398572721730594, 'net': 5.001142632594234, 'price': 3.630164326923022, 'american': 9.190850598702724, 'press': 10.658532953247773, 'aap': 10.278899187358402, 'publish': 9.14153745273487, 'critiqu': 8.406041984141751, 'bibl': 8.176900170514724, 'list': 4.534880377644629, 'biblic': 3.7267582133376056, 'contradict': 7.260328653846044, 'handbook': 5.85013899389411, 'ball': 7.341046619373188, 'foot': 6.9606232904412275, 'isbn': 12.730389120475643, 'edit': 8.002714565183737, 'absurd': 4.48181029651007, 'atroc': 6.004810317347688, 'immor': 6.471399135264356, 'base': 6.491261062918671, 'king': 3.4654228915253715, 'jame': 6.642996502512147, 'austin': 5.9170877015304155, 'tx': 6.699514293020976, 'cameron': 6.485263331265889, 'road': 5.485545421494976, 'fax': 5.485545421494976, 'prometheu': 15.122389923222869, 'includ': 7.187703148214103, 'haught': 10.278899187358402, 'holi': 5.353817493585452, 'horror': 8.31045021612701, 'east': 3.3585737824217086, 'amherst': 4.823168983647678, 'street': 5.90677201739468, 'buffalo': 9.710828402649216, 'york': 5.846832846839902, 'altern': 6.084713511462433, 'newer': 5.043904289511285, 'older': 4.631684734517705, 'glenn': 5.85013899389411, 'drive': 3.279476465571499, 'ny': 6.560766454398033, 'african': 10.406441243422192, 'human': 6.828538323928206, 'promot': 4.342715969729476, 'black': 5.023889041182247, 'secular': 10.158345295080712, 'uncov': 6.485263331265889, 'histori': 9.235483223182651, 'freethought': 9.833450236964628, 'quarterli': 5.85013899389411, 'newslett': 5.243310306928879, 'aah': 6.965716345184091, 'examin': 6.560766454398033, 'norm': 7.865001265733237, 'allen': 7.044102341612765, 'jr': 8.376089292551796, 'unit': 3.2398572721730594, 'kingdom': 3.9548198641252057, 'rationalist': 6.485263331265889, 'associ': 5.981102640042688, 'nation': 5.649974111030023, 'societi': 6.60033792562012, 'islington': 6.965716345184091, 'high': 3.2115616217665113, 'holloway': 6.965716345184091, 'london': 10.810916212239182, 'ew': 6.485263331265889, 'nl': 4.020883846535235, 'british': 3.9197163035088547, 'humanist': 5.369685979975908, 'south': 3.5354973799003195, 'place': 2.956674227200622, 'ethic': 4.656008183907014, 'lamb': 5.043904289511285, 'conduit': 6.485263331265889, 'passag': 3.7464698880259792, 'conway': 6.485263331265889, 'hall': 4.282404279092476, 'wc': 8.90259839538105, 'rh': 6.004810317347688, 'red': 3.911211323423629, 'lion': 4.924786768444069, 'squar': 4.734561642604129, 'rl': 6.004810317347688, 'freethink': 6.485263331265889, 'monthli': 5.524357303429486, 'magazin': 4.093914190905799, 'found': 4.408779952139505, 'germani': 8.40302130095835, 'ibka': 12.408432669530564, 'international': 10.278899187358402, 'bund': 6.965716345184091, 'der': 10.272922395650431, 'konfessionslosen': 10.278899187358402, 'und': 11.048714606858972, 'atheisten': 10.278899187358402, 'postfach': 12.408432669530564, 'berlin': 8.222514313858593, 'journal': 7.927796201578581, 'miz': 10.278899187358402, 'materialien': 6.965716345184091, 'informationen': 6.965716345184091, 'zur': 6.965716345184091, 'zeit': 6.485263331265889, 'politisch': 6.965716345184091, 'konfessionslosesn': 6.965716345184091, 'hrsg': 6.965716345184091, 'vertrieb': 6.965716345184091, 'ibdk': 6.965716345184091, 'ucherdienst': 6.965716345184091, 'hannov': 6.965716345184091, 'thoma': 3.733266685387286, 'disch': 6.965716345184091, 'santa': 6.764797592984889, 'clau': 6.004810317347688, 'compromis': 4.200763300009462, 'short': 5.701349569723765, 'stori': 8.36485102386919, 'ultim': 6.858353007703594, 'proof': 3.630164326923022, 'exist': 7.814891090015535, 'charact': 6.908298530536346, 'event': 3.3178974785841833, 'fictiti': 6.485263331265889, 'similar': 5.187828929780583, 'live': 5.115191297102257, 'dead': 5.457905918713506, 'god': 6.441901765649016, 'uh': 4.54212198714707, 'walter': 5.00188250382671, 'miller': 4.855414201324608, 'canticl': 6.965716345184091, 'leibowitz': 10.278899187358402, 'gem': 4.855414201324608, 'post': 2.762616350558193, 'atom': 9.042858979817018, 'doomsday': 9.833450236964628, 'monk': 5.72376332084708, 'spent': 4.051245510932032, 'copi': 3.5019127469649414, 'blueprint': 6.965716345184091, 'saint': 4.268112078302744, 'fill': 4.268112078302744, 'sheet': 5.369685979975908, 'paper': 7.479673700069256, 'ink': 5.72376332084708, 'leav': 3.4181933639841713, 'white': 3.1639448147912095, 'letter': 3.6472799417206967, 'edgar': 6.485263331265889, 'pangborn': 6.965716345184091, 'davi': 4.426328919361774, 'set': 4.58612810178925, 'cleric': 6.004810317347688, 'church': 2.5540073031054105, 'forbid': 5.303621997565879, 'produc': 3.653080370386037, 'substanc': 4.563451275593083, 'philip': 9.312016367814028, 'dick': 10.885432648692946, 'wrote': 5.947899634998772, 'philosoph': 8.144503156981205, 'thought': 4.458102619205071, 'provok': 5.442716324346473, 'novel': 7.805602352031574, 'bizarr': 5.72376332084708, 'time': 3.0755419112100877, 'approach': 3.560523462072106, 'sf': 4.342715969729476, 'truth': 2.746685604521294, 'technolog': 4.935599603178305, 'believ': 4.727549759465898, 'met': 4.426328919361774, 'sort': 3.1468993530405616, 'remain': 3.7876590643845423, 'sceptic': 4.924786768444069, 'relev': 4.020883846535235, 'galact': 6.965716345184091, 'pot': 7.504102660880306, 'healer': 9.27225092932876, 'fallibl': 5.369685979975908, 'alien': 5.187828929780583, 'deiti': 7.303801958097368, 'summon': 6.004810317347688, 'group': 2.5056285675047567, 'earth': 5.124926753524352, 'craftsmen': 6.965716345184091, 'women': 5.258743084793207, 'remot': 4.6081859695571, 'planet': 4.327138973056492, 'rais': 3.39372680585469, 'giant': 5.442716324346473, 'cathedr': 6.965716345184091, 'beneath': 5.72376332084708, 'ocean': 5.616914211743417, 'demand': 4.151231720599504, 'faith': 4.215153796330184, 'earther': 5.72376332084708, 'joe': 3.733266685387286, 'fernwright': 6.965716345184091, 'unabl': 4.54212198714707, 'compli': 4.762857293010677, 'polish': 5.00188250382671, 'iron': 4.855414201324608, 'amus': 4.563451275593083, 'maze': 6.965716345184091, 'death': 3.0624577754786655, 'noteworthi': 6.485263331265889, 'descript': 3.7876590643845423, 'vali': 6.965716345184091, 'schizophren': 6.485263331265889, 'hero': 5.187828929780583, 'search': 3.720310286091261, 'hidden': 4.254108628685928, 'mysteri': 6.858353007703594, 'gnostic': 5.616914211743417, 'realiti': 3.447873924303103, 'fire': 4.631684734517705, 'brain': 6.226250887653522, 'pink': 4.656008183907014, 'laser': 4.762857293010677, 'beam': 5.303621997565879, 'unknown': 4.563451275593083, 'divin': 5.8864267639431604, 'origin': 4.466373265207319, 'accompani': 5.303621997565879, 'dogmat': 5.088638983475301, 'dismiss': 4.8892329660577065, 'friend': 3.2271386184394952, 'odd': 4.2137196993054875, 'invas': 5.442716324346473, 'invad': 4.631684734517705, 'make': 3.2966770300819537, 'young': 3.5305987928650873, 'woman': 5.95934723034719, 'pregnant': 5.043904289511285, 'return': 3.591798564572401, 'star': 4.426328919361774, 'termin': 4.656008183907014, 'ill': 4.8892329660577065, 'assist': 4.1755551699888125, 'man': 2.782239406907656, 'wire': 4.762857293010677, 'hour': 3.85443070094543, 'easi': 3.6415276499476676, 'listen': 3.7599294794896996, 'margaret': 6.004810317347688, 'atwood': 9.833450236964628, 'handmaid': 6.965716345184091, 'tale': 7.927796201578581, 'premis': 4.051245510932032, 'congress': 5.492565332208393, 'assassin': 5.442716324346473, 'fundamentalist': 7.3795983745434315, 'charg': 3.5812159593106676, 'diari': 6.204216334765282, 'life': 2.561202667170823, 'theocraci': 6.204216334765282, 'properti': 4.011051806783288, 'revok': 6.485263331265889, 'bank': 3.937045885642867, 'account': 3.5019127469649414, 'close': 3.2626924208258576, 'sin': 2.9439943520164293, 'luxuri': 5.524357303429486, 'outlaw': 5.303621997565879, 'radio': 3.928326938221304, 'read': 4.793432565342473, 'crime': 3.3435047719792728, 'punish': 3.1933198537063974, 'retroact': 6.485263331265889, 'doctor': 4.051245510932032, 'perform': 3.635822702676591, 'legal': 3.2115616217665113, 'abort': 3.9548198641252057, 'hunt': 4.707375915862382, 'hang': 4.521429489908509, 'style': 4.240382493407901, 'difficult': 3.7806219767282614, 'grow': 4.200763300009462, 'chill': 5.616914211743417, 'author': 2.8954744554933076, 'dull': 5.243310306928879, 'rambl': 5.85013899389411, 'work': 4.3156198688865235, 'critic': 3.831451341914381, 'worth': 4.051245510932032, 'll': 2.5034069400241674, 'fuss': 5.442716324346473, 'true': 2.5745913520639165, 'peter': 3.6648289089429653, 'rosa': 8.065301968516176, 'vicar': 6.004810317347688, 'christ': 2.8127495869313237, 'bantam': 6.004810317347688, 'cathol': 3.2146491421524104, 'enlight': 6.965716345184091, 'papal': 4.823168983647678, 'adulteri': 5.616914211743417, 'fallaci': 3.85443070094543, 'german': 3.739836850034628, 'translat': 3.540430832617034, 'gott': 6.485263331265889, 'erst': 6.965716345184091, 'diener': 6.965716345184091, 'die': 3.0674444673505623, 'dunkl': 6.965716345184091, 'seit': 6.965716345184091, 'de': 5.85013899389411, 'papsttum': 6.965716345184091, 'droemer': 6.965716345184091, 'knaur': 6.965716345184091, 'michael': 3.1468993530405616, 'martin': 6.98775089807233, 'justif': 6.787450195289392, 'templ': 6.388757760297084, 'univers': 3.7839452140147625, 'philadelphia': 5.616914211743417, 'detail': 3.6767800184608035, 'scholarli': 5.524357303429486, 'outstand': 5.72376332084708, 'appendix': 9.833450236964628, 'defin': 3.2084877933120004, 'terminolog': 5.442716324346473, 'usag': 4.962263310428272, 'tendenti': 10.278899187358402, 'argu': 3.483427726689465, 'neg': 4.48181029651007, 'belief': 5.567799280938398, 'posit': 6.038243932618904, 'great': 5.879637507927452, 'refut': 7.044102341612765, 'challeng': 4.001357282591869, 'argument': 6.944175830306424, 'attent': 4.358651089469357, 'paid': 4.139382762313235, 'contempori': 6.965716345184091, 'theist': 3.7599294794896996, 'platinga': 6.965716345184091, 'swinburn': 15.76867175911319, 'hardcov': 9.833450236964628, 'paperback': 8.90259839538105, 'case': 2.58324807522218, 'comprehens': 10.08780857902257, 'consid': 3.4307583095054275, 'contemporari': 4.962263310428272, 'defenc': 5.442716324346473, 'demonstr': 3.945875905443573, 'unsupport': 5.72376332084708, 'incoher': 9.27225092932876, 'turner': 5.616914211743417, 'creed': 6.834206710690857, 'john': 2.8574842808953393, 'hopkin': 5.369685979975908, 'baltimor': 5.369685979975908, 'md': 4.501336860453437, 'subtitl': 6.965716345184091, 'unbelief': 10.278899187358402, 'america': 3.653080370386037, 'agnost': 4.358651089469357, 'mainstream': 5.088638983475301, 'view': 5.404886754982717, 'focuss': 6.965716345184091, 'period': 3.8622629558112753, 'franc': 4.444333754525868, 'britain': 4.48181029651007, 'emphasi': 4.6081859695571, 'england': 4.240382493407901, 'develop': 3.30016896281006, 'religi': 6.139902662991145, 'intellectu': 4.311904355832583, 'fate': 5.187828929780583, 'singl': 3.7013187643825347, 'idea': 4.428298731837146, 'georg': 3.7139217875910897, 'seld': 6.965716345184091, 'editor': 4.408779952139505, 'ballantin': 6.485263331265889, 'dictionari': 4.631684734517705, 'quotat': 7.548950205708201, 'kind': 2.9783368396158187, 'concentr': 4.061668973228869, 'statement': 2.9939138362888036, 'explicitli': 4.296997390319128, 'implicitli': 5.303621997565879, 'person': 2.463541338098228, 'philosophi': 3.9823657608831424, 'obscur': 5.187828929780583, 'suppress': 5.043904289511285, 'opinion': 2.680621622111265, 'popular': 4.200763300009462, 'observ': 3.5656389626376828, 'trace': 4.001357282591869, 'express': 3.560523462072106, 'twist': 4.924786768444069, 'centuri': 5.992144062516587, 'number': 4.280931450485228, 'deriv': 4.444333754525868, 'cardiff': 6.965716345184091, 'men': 2.950305295587227, 'noy': 4.327138973056492, 'richard': 3.8701847240988965, 'revis': 7.994399156101974, 'clarendon': 6.965716345184091, 'oxford': 7.548950205708201, 'volum': 6.542301947678558, 'trilog': 6.485263331265889, 'began': 4.563451275593083, 'coher': 5.616914211743417, 'theism': 9.58471473950157, 'conclud': 4.327138973056492, 'reason': 2.38633539567496, 'attempt': 5.521102320775147, 'construct': 4.139382762313235, 'seri': 4.200763300009462, 'induct': 5.1364611978252155, 'reli': 4.2137196993054875, 'imput': 5.85013899389411, 'late': 4.226922901944181, 'western': 3.597151079050549, 'valu': 3.613461176987598, 'aesthet': 5.72376332084708, 'supposedli': 4.296997390319128, 'simpl': 3.4522196888866783, 'conceiv': 4.762857293010677, 'decis': 3.443555236310111, 'reject': 3.635822702676591, 'macki': 11.70027798778822, 'miracl': 7.015565353046012, 'rebut': 6.204216334765282, 'posthum': 6.965716345184091, 'review': 4.093914190905799, 'princip': 4.962263310428272, 'rang': 6.388757760297084, 'classic': 7.461014303439785, 'descart': 5.1364611978252155, 'anselm': 6.485263331265889, 'berkeley': 4.020883846535235, 'hume': 6.965716345184091, 'al': 3.83902679633991, 'moral': 4.157262293256351, 'newman': 5.442716324346473, 'kant': 6.485263331265889, 'sidgwick': 6.965716345184091, 'restat': 6.965716345184091, 'these': 6.965716345184091, 'plantinga': 6.965716345184091, 'push': 3.8781980755511563, 'concept': 3.5066120678839354, 'realm': 5.243310306928879, 'ration': 6.226250887653522, 'kierkegaard': 6.004810317347688, 'kung': 6.965716345184091, 'replac': 3.7876590643845423, 'leli': 6.965716345184091, 'axiarch': 6.965716345184091, 'delight': 5.524357303429486, 'formalist': 6.965716345184091, 'refreshingli': 6.965716345184091, 'direct': 3.443555236310111, 'compar': 3.5161073832277245, 'hand': 2.98496987760717, 'wave': 3.8466859591382905, 'illustr': 4.521429489908509, 'murder': 3.443555236310111, 'mad': 4.734561642604129, 'persecut': 4.631684734517705, 'ancient': 4.040976475990307, 'day': 2.490224662899237, 'librari': 3.405852138618528, 'catalog': 5.303621997565879, 'card': 3.6079817241004224, 'antholog': 12.408432669530564, 'gordon': 5.303621997565879, 'stein': 4.563451275593083, 'cover': 3.5066120678839354, 'wide': 3.8701847240988965, 'devil': 4.792357369750785, 'evil': 3.385759509163456, 'bibliographi': 5.187828929780583, 'edmund': 6.965716345184091, 'cohen': 6.204216334765282, 'mind': 3.019121966309452, 'studi': 3.1113455506541996, 'small': 3.3739776870272284, 'server': 5.753674329628646, 'carri': 3.492608618267119, 'moder': 4.16328675802526, 'articl': 1.64768846113368, 'file': 2.4388569309438695, 'send': 4.853880734175616, 'repli': 2.572137731163589}\n"
     ]
    }
   ],
   "source": [
    "compute_aik=aik_dic(nk_fik_dic,len(n_k))\n",
    "print(compute_aik['49960']) ###check the aik dict of 49960 doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $A_{ik}$\n",
    "Calculating $a_{ik}$is much easier when we calculate $A_{ik}$separated by files. $A_{ik}$is calculated as follows:\n",
    "\n",
    "$$A_{ik}=\\frac{a_{ik}}{\\sqrt{{{\\sum^{D}_{j=1}{a^2_{ij}}}}}}$$\n",
    "\n",
    "As you can see from the formula, $A_{ik}$ is acturally the value that taking the length of different documents into account to normalize the representation of the  documen. s$A_{ik}$is also computed using a custom function, **normalize_aik()**, which takes $a_{ik}$ from the dict and puts it into the dict in the same format as $a_{ik}$.\n",
    "Finally, we have completed the task of this report by calculating the TIFDI value of each word in each text and saving it to $A_{N*D}$ where D is the number of the unique words in the document  collection。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mathew': 0.05244944657509002, 'manti': 0.0700684258224514, 'uk': 0.046352486938326984, 'subject': 0.015642196303917423, 'alt': 0.048785108747537644, 'atheism': 0.0784030537755677, 'faq': 0.035815917812221966, 'atheist': 0.06298874562173093, 'resourc': 0.06754725559156029, 'summari': 0.024941746393127694, 'book': 0.07549733054062305, 'address': 0.057574196187537646, 'music': 0.062254458808365803, 'keyword': 0.02289742088737945, 'fiction': 0.06461006844966596, 'contact': 0.023587418439893506, 'expir': 0.03321993543991225, 'thu': 0.03302257918464186, 'apr': 0.014847846115745186, 'gmt': 0.02590382924000468, 'distribut': 0.018627355801184253, 'organ': 0.020397313200918796, 'consult': 0.02887133072975383, 'cambridg': 0.030400681542517648, 'supersed': 0.03699165637723045, 'line': 0.016037249240763184, 'archiv': 0.06629077694036212, 'modifi': 0.03214113524426631, 'decemb': 0.03230503422483298, 'version': 0.04513912270150432, 'usa': 0.048932430976633044, 'freedom': 0.040068631837891944, 'religion': 0.05146265477857459, 'foundat': 0.04342680029991036, 'darwin': 0.09096572228373041, 'fish': 0.09116796735856016, 'bumper': 0.037961810272559224, 'sticker': 0.03265050665220348, 'assort': 0.07835360835163432, 'paraphernalia': 0.045233358028936466, 'write': 0.033455877891827294, 'ffrf': 0.0485844175132707, 'box': 0.05120583051232902, 'madison': 0.03434935973058123, 'wi': 0.038531239060267994, 'telephon': 0.07623578251421215, 'evolut': 0.06014926566623617, 'design': 0.047510215487172665, 'sell': 0.04000708458817141, 'symbol': 0.03321993543991225, 'christian': 0.04759881658630071, 'stick': 0.028790075759932074, 'car': 0.02326854089161067, 'feet': 0.02855419693510569, 'word': 0.02060733284990639, 'written': 0.0369206320106704, 'delux': 0.038531239060267994, 'mould': 0.0485844175132707, 'plastic': 0.03125969130389075, 'postpaid': 0.0485844175132707, 'laurel': 0.045233358028936466, 'canyon': 0.037452438864622045, 'north': 0.026619600375944907, 'hollywood': 0.03618402389958689, 'peopl': 0.03255672970431795, 'san': 0.025561416658875413, 'francisco': 0.02986887595557802, 'bay': 0.03321993543991225, 'area': 0.03516990690383026, 'lynn': 0.055759265396491314, 'gold': 0.03198261098009508, 'mail': 0.04420528715216667, 'figmo': 0.0485844175132707, 'netcom': 0.022597328199200777, 'net': 0.03488192594482608, 'price': 0.02531963843502564, 'american': 0.06410426446638004, 'press': 0.07434104253147829, 'aap': 0.07169317625755854, 'publish': 0.06376031556667333, 'critiqu': 0.05863038819747289, 'bibl': 0.05703217187752463, 'list': 0.03162984404217835, 'biblic': 0.025993360630165004, 'contradict': 0.05063927687005128, 'handbook': 0.04080349834895629, 'ball': 0.05120226783087383, 'foot': 0.0485488945195421, 'isbn': 0.08879180682733383, 'edit': 0.05581726363911303, 'absurd': 0.03125969130389075, 'atroc': 0.04188229854460223, 'immor': 0.045136658155779844, 'base': 0.04527519095527329, 'king': 0.02417060131056268, 'jame': 0.046333513973819095, 'austin': 0.04127045161012733, 'tx': 0.04672771376533185, 'cameron': 0.045233358028936466, 'road': 0.03826053428520409, 'fax': 0.03826053428520409, 'prometheu': 0.1054755131302896, 'includ': 0.05013272912781166, 'haught': 0.07169317625755854, 'holi': 0.037341759484369845, 'horror': 0.057963655568994445, 'east': 0.02342535107779912, 'amherst': 0.03364059689289621, 'street': 0.04119850186653317, 'buffalo': 0.06773100111092285, 'york': 0.04078043866336444, 'altern': 0.04243960664489527, 'newer': 0.03518017957593376, 'older': 0.03230503422483298, 'glenn': 0.04080349834895629, 'drive': 0.02287366380321078, 'ny': 0.0457599765525782, 'african': 0.0725827554760101, 'human': 0.0476276294489752, 'promot': 0.030289537408561978, 'black': 0.03504057739673763, 'secular': 0.07085233802283505, 'uncov': 0.045233358028936466, 'histori': 0.06441556770570087, 'freethought': 0.06858626280970592, 'quarterli': 0.04080349834895629, 'newslett': 0.03657099492424649, 'aah': 0.0485844175132707, 'examin': 0.0457599765525782, 'norm': 0.05485674212114181, 'allen': 0.04913114347639687, 'jr': 0.05842147442583206, 'unit': 0.022597328199200777, 'kingdom': 0.027584043039776913, 'rationalist': 0.045233358028936466, 'associ': 0.041716942444040894, 'nation': 0.03940739007255665, 'societi': 0.04603597930436947, 'islington': 0.0485844175132707, 'high': 0.022399971943930386, 'holloway': 0.0485844175132707, 'london': 0.07540388395510157, 'ew': 0.045233358028936466, 'nl': 0.028044825527168513, 'british': 0.027339203031847746, 'humanist': 0.037452438864622045, 'south': 0.024659356239923404, 'place': 0.020622185570958053, 'ethic': 0.03247468520714869, 'lamb': 0.03518017957593376, 'conduit': 0.045233358028936466, 'passag': 0.026130845446584183, 'conway': 0.045233358028936466, 'hall': 0.02986887595557802, 'wc': 0.06209376551676622, 'rh': 0.04188229854460223, 'red': 0.027279882571047135, 'lion': 0.03434935973058123, 'squar': 0.03302257918464186, 'rl': 0.04188229854460223, 'freethink': 0.045233358028936466, 'monthli': 0.038531239060267994, 'magazin': 0.02855419693510569, 'found': 0.03075031989595357, 'germani': 0.058609319562793395, 'ibka': 0.08654622778582993, 'international': 0.07169317625755854, 'bund': 0.0485844175132707, 'der': 0.07165148938296585, 'konfessionslosen': 0.07169317625755854, 'und': 0.07706247812053599, 'atheisten': 0.07169317625755854, 'postfach': 0.08654622778582993, 'berlin': 0.057350321006043314, 'journal': 0.05529472369111179, 'miz': 0.07169317625755854, 'materialien': 0.0485844175132707, 'informationen': 0.0485844175132707, 'zur': 0.0485844175132707, 'zeit': 0.045233358028936466, 'politisch': 0.0485844175132707, 'konfessionslosesn': 0.0485844175132707, 'hrsg': 0.0485844175132707, 'vertrieb': 0.0485844175132707, 'ibdk': 0.0485844175132707, 'ucherdienst': 0.0485844175132707, 'hannov': 0.0485844175132707, 'thoma': 0.02603875586416039, 'disch': 0.0485844175132707, 'santa': 0.04718305115561816, 'clau': 0.04188229854460223, 'compromis': 0.029299447167869246, 'short': 0.03976572317304792, 'stori': 0.05834308984759991, 'ultim': 0.0478355806449166, 'proof': 0.02531963843502564, 'exist': 0.05450723410529856, 'charact': 0.04818394024125627, 'event': 0.023141642349133285, 'fictiti': 0.045233358028936466, 'similar': 0.03618402389958689, 'live': 0.03567739157373008, 'dead': 0.03806775452265712, 'god': 0.04493092015986995, 'uh': 0.031680352756874704, 'walter': 0.034887086392234985, 'miller': 0.03386550055546143, 'canticl': 0.0485844175132707, 'leibowitz': 0.07169317625755854, 'gem': 0.03386550055546143, 'post': 0.01926867238820364, 'atom': 0.0630720538158015, 'doomsday': 0.06858626280970592, 'monk': 0.03992205440858073, 'spent': 0.028256591798769798, 'copi': 0.024425110435514437, 'blueprint': 0.0485844175132707, 'saint': 0.029769190838363633, 'fill': 0.029769190838363633, 'sheet': 0.037452438864622045, 'paper': 0.052169162782294026, 'ink': 0.03992205440858073, 'leav': 0.02384118521445612, 'white': 0.02206785465461005, 'letter': 0.025439016275597835, 'edgar': 0.045233358028936466, 'pangborn': 0.0485844175132707, 'davi': 0.030872720279231148, 'set': 0.03198728622085228, 'cleric': 0.04188229854460223, 'church': 0.01781366782639732, 'forbid': 0.03699165637723045, 'produc': 0.025479473054781456, 'substanc': 0.03182912009159952, 'philip': 0.06494937041429738, 'dick': 0.07592362054511845, 'wrote': 0.04148535841451547, 'philosoph': 0.05680620947054494, 'thought': 0.03109433520332942, 'provok': 0.037961810272559224, 'novel': 0.054442447096752604, 'bizarr': 0.03992205440858073, 'time': 0.021451262854982712, 'approach': 0.024833907939232278, 'sf': 0.030289537408561978, 'truth': 0.01915755875991332, 'technolog': 0.03442477699582679, 'believ': 0.032973672763383755, 'met': 0.030872720279231148, 'sort': 0.021948966116897412, 'remain': 0.026418131354029394, 'sceptic': 0.03434935973058123, 'relev': 0.028044825527168513, 'galact': 0.0485844175132707, 'pot': 0.052339549684752365, 'healer': 0.06467201478133333, 'fallibl': 0.037452438864622045, 'alien': 0.03618402389958689, 'deiti': 0.05094249409276923, 'summon': 0.04188229854460223, 'group': 0.01747623624395694, 'earth': 0.03574529435013588, 'craftsmen': 0.0485844175132707, 'women': 0.03667863532847691, 'remot': 0.03214113524426631, 'planet': 0.030180891108244803, 'rais': 0.023670536078549624, 'giant': 0.037961810272559224, 'cathedr': 0.0485844175132707, 'beneath': 0.03992205440858073, 'ocean': 0.03917680417581716, 'demand': 0.028953974740498746, 'faith': 0.02939981787589449, 'earther': 0.03992205440858073, 'joe': 0.02603875586416039, 'fernwright': 0.0485844175132707, 'unabl': 0.031680352756874704, 'compli': 0.03321993543991225, 'polish': 0.034887086392234985, 'iron': 0.03386550055546143, 'amus': 0.03182912009159952, 'maze': 0.0485844175132707, 'death': 0.02136000373938361, 'noteworthi': 0.045233358028936466, 'descript': 0.026418131354029394, 'vali': 0.0485844175132707, 'schizophren': 0.045233358028936466, 'hero': 0.03618402389958689, 'search': 0.025948387683535013, 'hidden': 0.029671519700307628, 'mysteri': 0.0478355806449166, 'gnostic': 0.03917680417581716, 'realiti': 0.024048200927285105, 'fire': 0.03230503422483298, 'brain': 0.04342680029991036, 'pink': 0.03247468520714869, 'laser': 0.03321993543991225, 'beam': 0.03699165637723045, 'unknown': 0.03182912009159952, 'divin': 0.041056597970491625, 'origin': 0.031152021232815175, 'accompani': 0.03699165637723045, 'dogmat': 0.03549219472860054, 'dismiss': 0.03410137938028781, 'friend': 0.022508618244247554, 'odd': 0.029389815348494625, 'invas': 0.037961810272559224, 'invad': 0.03230503422483298, 'make': 0.022993634150297575, 'young': 0.024625189617863155, 'woman': 0.041565203002547686, 'pregnant': 0.03518017957593376, 'return': 0.025052045250938234, 'star': 0.030872720279231148, 'termin': 0.03247468520714869, 'ill': 0.03410137938028781, 'assist': 0.029123625722814454, 'man': 0.01940553911020674, 'wire': 0.03321993543991225, 'hour': 0.026883849581410473, 'easi': 0.025398895241190194, 'listen': 0.02622472328754501, 'margaret': 0.04188229854460223, 'atwood': 0.06858626280970592, 'handmaid': 0.0485844175132707, 'tale': 0.05529472369111179, 'premis': 0.028256591798769798, 'congress': 0.03830949669712348, 'assassin': 0.037961810272559224, 'fundamentalist': 0.05147115827605474, 'charg': 0.02497823378820624, 'diari': 0.043273113892914966, 'life': 0.017863853988823484, 'theocraci': 0.043273113892914966, 'properti': 0.027976249102197388, 'revok': 0.045233358028936466, 'bank': 0.027460073249928257, 'account': 0.024425110435514437, 'close': 0.022756598594540975, 'sin': 0.020533746088292226, 'luxuri': 0.038531239060267994, 'outlaw': 0.03699165637723045, 'radio': 0.027399260411619338, 'read': 0.03343319158227254, 'crime': 0.023320247875405112, 'punish': 0.022272739419421178, 'retroact': 0.045233358028936466, 'doctor': 0.028256591798769798, 'perform': 0.025359104424801177, 'legal': 0.022399971943930386, 'abort': 0.027584043039776913, 'hunt': 0.03283296441525266, 'hang': 0.03153602690790075, 'style': 0.029575782771879246, 'difficult': 0.026369049136518972, 'grow': 0.029299447167869246, 'chill': 0.03917680417581716, 'author': 0.020195329937882967, 'dull': 0.03657099492424649, 'rambl': 0.04080349834895629, 'work': 0.030100547761108723, 'critic': 0.026723573348783846, 'worth': 0.028256591798769798, 'll': 0.017460740856013023, 'fuss': 0.037961810272559224, 'true': 0.017957237271254933, 'peter': 0.025561416658875413, 'rosa': 0.056253797713124956, 'vicar': 0.04188229854460223, 'christ': 0.01961834124730492, 'bantam': 0.04188229854460223, 'cathol': 0.02242150675414599, 'enlight': 0.0485844175132707, 'papal': 0.03364059689289621, 'adulteri': 0.03917680417581716, 'fallaci': 0.026883849581410473, 'german': 0.026084581391147013, 'translat': 0.02469376604283428, 'gott': 0.045233358028936466, 'erst': 0.0485844175132707, 'diener': 0.0485844175132707, 'die': 0.02139478487428896, 'dunkl': 0.0485844175132707, 'seit': 0.0485844175132707, 'de': 0.04080349834895629, 'papsttum': 0.0485844175132707, 'droemer': 0.0485844175132707, 'knaur': 0.0485844175132707, 'michael': 0.021948966116897412, 'martin': 0.048738103920266104, 'justif': 0.04734104832828296, 'templ': 0.04456025181559681, 'univers': 0.026392228022913716, 'philadelphia': 0.03917680417581716, 'detail': 0.0256447731531379, 'scholarli': 0.038531239060267994, 'outstand': 0.03992205440858073, 'appendix': 0.06858626280970592, 'defin': 0.022378532632078223, 'terminolog': 0.037961810272559224, 'usag': 0.03461075078822499, 'tendenti': 0.07169317625755854, 'argu': 0.02429618127757852, 'neg': 0.03125969130389075, 'belief': 0.038834237785496634, 'posit': 0.042115491032326466, 'great': 0.041009244326942855, 'refut': 0.04913114347639687, 'challeng': 0.027908631819556516, 'argument': 0.048434176918275625, 'attent': 0.030400681542517648, 'paid': 0.02887133072975383, 'contempori': 0.0485844175132707, 'theist': 0.02622472328754501, 'platinga': 0.0485844175132707, 'swinburn': 0.10998319403346722, 'hardcov': 0.06858626280970592, 'paperback': 0.06209376551676622, 'case': 0.018017616108315766, 'comprehens': 0.07036035915186752, 'consid': 0.0239288230867129, 'contemporari': 0.03461075078822499, 'defenc': 0.037961810272559224, 'demonstr': 0.027521660794896916, 'unsupport': 0.03992205440858073, 'incoher': 0.06467201478133333, 'turner': 0.03917680417581716, 'creed': 0.04766716526344943, 'john': 0.019930356399971705, 'hopkin': 0.037452438864622045, 'baltimor': 0.037452438864622045, 'md': 0.03139588501150275, 'subtitl': 0.0485844175132707, 'unbelief': 0.07169317625755854, 'america': 0.025479473054781456, 'agnost': 0.030400681542517648, 'mainstream': 0.03549219472860054, 'view': 0.03769795692263253, 'focuss': 0.0485844175132707, 'period': 0.026938477924227742, 'franc': 0.030998300246246994, 'britain': 0.03125969130389075, 'emphasi': 0.03214113524426631, 'england': 0.029575782771879246, 'develop': 0.023017989652184736, 'religi': 0.04282453945685622, 'intellectu': 0.030074632833118085, 'fate': 0.03618402389958689, 'singl': 0.025815925783827166, 'idea': 0.030886459310076483, 'georg': 0.02590382924000468, 'seld': 0.0485844175132707, 'editor': 0.03075031989595357, 'ballantin': 0.045233358028936466, 'dictionari': 0.03230503422483298, 'quotat': 0.052652351948638695, 'kind': 0.02077327777079127, 'concentr': 0.028329293272540475, 'statement': 0.02088192407110845, 'explicitli': 0.029970659860279143, 'implicitli': 0.03699165637723045, 'person': 0.01718268660395799, 'philosophi': 0.02777616991984867, 'obscur': 0.03618402389958689, 'suppress': 0.03518017957593376, 'opinion': 0.018696776272521726, 'popular': 0.029299447167869246, 'observ': 0.024869587487889065, 'trace': 0.027908631819556516, 'express': 0.024833907939232278, 'twist': 0.03434935973058123, 'centuri': 0.04179395406105616, 'number': 0.029858603283474523, 'deriv': 0.030998300246246994, 'cardiff': 0.0485844175132707, 'men': 0.02057776360237867, 'noy': 0.030180891108244803, 'richard': 0.026993730604477243, 'revis': 0.055759265396491314, 'clarendon': 0.0485844175132707, 'oxford': 0.052652351948638695, 'volum': 0.045631190472413485, 'trilog': 0.045233358028936466, 'began': 0.03182912009159952, 'coher': 0.03917680417581716, 'theism': 0.06685138463490464, 'conclud': 0.030180891108244803, 'reason': 0.01664419127120001, 'attempt': 0.03850853623568539, 'construct': 0.02887133072975383, 'seri': 0.029299447167869246, 'induct': 0.035825744691482926, 'reli': 0.029389815348494625, 'imput': 0.04080349834895629, 'late': 0.02948190493091842, 'western': 0.025089377922161912, 'valu': 0.025203137450771455, 'aesthet': 0.03992205440858073, 'supposedli': 0.029970659860279143, 'simpl': 0.024078511728138886, 'conceiv': 0.03321993543991225, 'decis': 0.024018078979998785, 'reject': 0.025359104424801177, 'macki': 0.08160699669791258, 'miracl': 0.04893210393783496, 'rebut': 0.043273113892914966, 'posthum': 0.0485844175132707, 'review': 0.02855419693510569, 'princip': 0.03461075078822499, 'rang': 0.04456025181559681, 'classic': 0.052039017385687586, 'descart': 0.035825744691482926, 'anselm': 0.045233358028936466, 'berkeley': 0.028044825527168513, 'hume': 0.0485844175132707, 'al': 0.026776410562133354, 'moral': 0.028996036725983835, 'newman': 0.037961810272559224, 'kant': 0.045233358028936466, 'sidgwick': 0.0485844175132707, 'restat': 0.0485844175132707, 'these': 0.0485844175132707, 'plantinga': 0.0485844175132707, 'push': 0.027049622058183412, 'concept': 0.024457887218007898, 'realm': 0.03657099492424649, 'ration': 0.04342680029991036, 'kierkegaard': 0.04188229854460223, 'kung': 0.0485844175132707, 'replac': 0.026418131354029394, 'leli': 0.0485844175132707, 'axiarch': 0.0485844175132707, 'delight': 0.038531239060267994, 'formalist': 0.0485844175132707, 'refreshingli': 0.0485844175132707, 'direct': 0.024018078979998785, 'compar': 0.02452411506051856, 'hand': 0.02081954182622844, 'wave': 0.026829831623910567, 'illustr': 0.03153602690790075, 'murder': 0.024018078979998785, 'mad': 0.03302257918464186, 'persecut': 0.03230503422483298, 'ancient': 0.028184967423566517, 'day': 0.01736879722467982, 'librari': 0.023755107743586332, 'catalog': 0.03699165637723045, 'card': 0.025164919410641397, 'antholog': 0.08654622778582993, 'gordon': 0.03699165637723045, 'stein': 0.03182912009159952, 'cover': 0.024457887218007898, 'wide': 0.026993730604477243, 'devil': 0.03342569231745232, 'evil': 0.02361496584718833, 'bibliographi': 0.03618402389958689, 'edmund': 0.0485844175132707, 'cohen': 0.043273113892914966, 'mind': 0.021057745516163233, 'studi': 0.021700985766603998, 'small': 0.023532790097076237, 'server': 0.04013067745133374, 'carri': 0.02436021607995189, 'moder': 0.029038056110225485, 'articl': 0.011492283084834914, 'file': 0.017010518016575864, 'send': 0.0338548049421867, 'repli': 0.017940123777633675}\n"
     ]
    }
   ],
   "source": [
    "def sq(i):\n",
    "    return i**2 \n",
    "\n",
    "def normalize_aik(dic):\n",
    "    dic1={}\n",
    "    dic2={}\n",
    "    for i in dic:\n",
    "        dic1={}\n",
    "        l=list(dic.get(i).values())   ##获取全文件的aij,并将其写入一个列表\n",
    "        sigma=pow(sum(map(sq,l)),1/2) ##使用map()分别计算list中每个元素的平方，并计算文档内全单词的aij的平方和的开方\n",
    "        for w in dic.get(i):\n",
    "            n_aik=dic.get(i).get(w)/sigma\n",
    "            dic1.update({w:n_aik})\n",
    "        dic2.update({i:dic1})\n",
    "    return dic2\n",
    "A_nd=normalize_aik(compute_aik)  \n",
    "print(A_nd['49960'])  ###check the values in 49960 doc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the Data\n",
    "Finally, the dataset is save into .npz file, where A is a matrix represented with the numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np   ###Save data to a compressed file as .npz\n",
    "np.savez('train-20ng.npz',X=A_nd)\n",
    "data = np.load('train-20ng.npz',allow_pickle=True)\n",
    "print(data['X']) ###Check whether the file is saved successfully"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
